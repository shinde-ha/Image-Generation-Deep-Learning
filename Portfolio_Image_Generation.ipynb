{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation using General Adversarial Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Image generation is a widely used technique to generate machine learned images which are not present in actual. We will use some image generation techniques to provide the machine an ability to produce images which are displayed similar to the real images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Generative Model is a powerful way of learning any kind of data distribution using unsupervised learning and it has achieved tremendous success in just few years. All types of generative models aim at learning the true data distribution of the training set so as to generate new data points with some variations. But it is not always possible to learn the exact distribution of our data either implicitly or explicitly and so we try to model a distribution which is as similar as possible to the true data distribution. For this, we can leverage the power of neural networks to learn a function which can approximate the model distribution to the true distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Auto Encoder is one of the most popular approach to learn the complicated data distribution such as images using neural networks in an unsupervised fashion. It is a probabilistic graphical model rooted in Bayesian inference i.e., the model aims to learn the underlying probability distribution of the training data so that it could easily sample new data from that learned distribution. The idea is to learn a low-dimensional latent representation of the training data called latent variables (variables which are not directly observed but are rather inferred through a mathematical model) which we assume to have generated our actual training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the MNIST dataset for generation of handwritten letters. After using VAE (MNIST_VAE.ipynb), the output images looks more like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST VAE](images/MNIST_VAE.png \"MNIST VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best thing of VAE is that it learns both the generative model and an inference model. Although both VAE and GANs are very exciting approaches to learn the underlying data distribution using unsupervised learning but GANs yield better results as compared to VAE. In VAE, we optimize the lower variational bound whereas in GAN, there is no such assumption. In fact, GANs don’t deal with any explicit probability density estimation. The failure of VAE in generating sharp images implies that the model is not able to learn the true posterior distribution. VAE and GAN mainly differ in the way of training. Let’s now dive into Generative Adversarial Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks don’t work with any explicit density estimation like Variational Autoencoders. Instead, it is based on game theory approach with an objective to find Nash equilibrium between the two networks, Generator and Discriminator. The idea is to sample from a simple distribution like Gaussian and then learn to transform this noise to data distribution using universal function approximators such as neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator model G learns to capture the data distribution and a discriminator model D estimates the probability that a sample came from the data distribution rather than model distribution. Basically the task of the Generator is to generate natural looking images and the task of the Discriminator is to decide whether the image is fake or real. This can be thought of as a mini-max two player game where the performance of both the networks improves over time. In this game, the generator tries to fool the discriminator by generating real images as far as possible and the generator tries to not get fooled by the discriminator by improving its discriminative capability. Below image shows the basic architecture of GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Vanilla GAN](images/vanillaGAN.png \"Vanilla GAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further implementation, we use DC-GAN (Deep convolutional GAN) on MNIST data (MNIST_DCGAN.ipynb) to generate more accurate images. Generation of images take a lot of time in this architecture which is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DCGAN](images/DCGAN.jpg \"DCGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model for higher number of epoch and batch sizes, the images generated are quite accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST DCGAN](images/DCGAN_MNIST.gif \"MNIST DCGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important finding to understand is that in DCGAN, the loss function generates fluctuating error rate indefinitely. The model does not know when to stop training and it may provide underuse or overuse of the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![error DCGAN](images/error_dcgan.jpg \"error DCGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to rectify this issue we use a loss function known as WGAN. (Wasserstein GAN) \n",
    "WGANs Change the loss function of DCGAN to include the Wasserstein distance. As a result, WassGANs have loss functions that correlate with image quality. Also, training stability improves and is not as dependent on the architecture. By training, we will know when to stop as the loss will be stablized w.r.t. time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WGAN](images/WGAN.jpg \"WGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The techniques of WGAN is used on the infamous CELEBA-HQ dataset to create machine generated faces. The NVIDIA project needs high requirements w.r.t. computation and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture involves upsampling the images to provide random values to combine and generate images from points in random manner in the distribution space. The result for each upsample is displayed on the architecture below. This takes a lot of computation and time. For NVIDIA's Progressive GAN it takes, for maximum resource allocation, about 2 days on 8 NVIDIA Tesla \n",
    "V100 machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Arch Celeb](images/celeb_arch.png \"Architecture used for ProgressiveGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used this architecture and modeling to create images based on Pokemon dataset (PokemonGAN). The output generated does provide good results for generating our imaginary pokemons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pokemon](images/pokemon.jpg \"pokemon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further epochs and longer execution, the images produced will be real-like machine generated pokemons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to understand GANs and there working is quite an interesting topic to learn! The Celeba-HQ is an ultimate example of how image generation has progressed these years. The real looking celebrities below are actually machine generated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![celeb](images/celeb.png \"Machine generated celebrities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latent space exploration on the training results gives a visual representation as if all the faces are related to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![celebgif](images/celeb.gif \"Latent space interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION:\n",
    "\n",
    "We can conclude by saying that GANs are better for image generation than VAE.\n",
    "\n",
    "We have implemented different types of GANs like DC-GAN, W-GAN in our research to prove that GANs are better. In the future, we would also be implementing Progressive GANs on a bigger dataset. \n",
    "\n",
    "A disadvantage of VAEs is that, because of the injected noise and imperfect reconstruction, and with the standard decoder (with factorized output distribution), the generated samples are much more blurred than those coming from GANs.\n",
    "\n",
    "Though GANs are more difficult to train than VAEs, they tend to yield nicer images. Compared to the VAE, there is no variational lower bound. If the discriminator net fits perfectly, then the generator net recovers the training distribution perfectly. In other words, GANs are asymptotically consistent, while the VAE has some bias.\n",
    "\n",
    "Compared to all other generative models we can say that:\n",
    "\n",
    "In terms of actual results, they seem to produce better samples than other models.\n",
    "\n",
    "The GAN framework can train any kind of generator net (in theory- in practice, it’s pretty hard to use REINFORCE to train generator nets with discrete outputs). Most other frameworks require that the generator net has some particular functional form, like the output layer being Gaussian. Essentially all of the other frameworks require that the generator net put non-zero mass everywhere. GANs can learn models that generate points only on a thin manifold that goes near the data.\n",
    "\n",
    "There’s no need to design the model to obey any kind of factorization. Any generator net and any discriminator net will work.\n",
    "\n",
    "Autoencoders are more suitable for compressing data to lower dimensions or generating semantic vectors from it. Where GANs are more suitable for generating data.\n",
    "\n",
    "Therefore we concluse our research by saying that GANs are better for image generation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES: \n",
    "https://github.com/nikbearbrown/CSYE_7245\n",
    "\n",
    "Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen(2018). PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION. In ICLR 2018.\n",
    "\n",
    "Junbo Jake Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network. In ICLR, 2017.\n",
    "\n",
    "Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial networks. In ICLR, 2017.\n",
    "\n",
    "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein GAN. CoRR, abs/1701.07875,2017.\n",
    "\n",
    "Theano. (2012).  new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.\n",
    "\n",
    "Bengio, Y. (2009). Learning deep architectures for AI. Now Publishers. \n",
    "\n",
    "Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013). Better mixing via deep representations. In ICML’13\n",
    "\n",
    "Bengio, Y., Thibodeau-Laufer, E., and Yosinski, J. (2014a). Deep generative stochastic networks trainable by backprop. In ICML’14\n",
    "\n",
    "https://www.doc.ic.ac.uk/~js4416/163/website/autoencoders/variational.html\n",
    "\n",
    "https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a\n",
    "\n",
    "http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them\n",
    "\n",
    "http://guimperarnau.com/blog/2017/11/Fantastic-GANs-and-where-to-find-them-II\n",
    "\n",
    "http://kvfrans.com/variational-autoencoders-explained/\n",
    "\n",
    "http://kvfrans.com/generative-adversial-networks-explained/\n",
    "\n",
    "https://drive.google.com/open?id=1jYlrX4DgTs2VAfRcyl3pcNI4ONkBg3-g -- Slides for Progressive GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
